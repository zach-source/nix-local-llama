#!/usr/bin/env bash
# ROCm VRAM Detection Fix for AMD APUs with Large Unified Memory
# Specifically for Strix Halo (gfx1151) with 96GB+ VRAM configs
#
# Problem: ROCm may only detect ~26GB of 96GB configured VRAM
# Solution: TTM parameters or UMA build with proper runtime flags

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

log() { echo -e "${GREEN}[INFO]${NC} $*"; }
warn() { echo -e "${YELLOW}[WARN]${NC} $*"; }
error() { echo -e "${RED}[ERROR]${NC} $*" >&2; }
header() { echo -e "\n${BLUE}=== $* ===${NC}"; }

# Detect system info
detect_system() {
    header "System Detection"

    # Check for AMD GPU
    if ! lspci | grep -qi "AMD.*VGA\|AMD.*Display"; then
        error "No AMD GPU detected"
        exit 1
    fi

    log "AMD GPU detected"

    # Get GPU info
    if command -v rocm-smi &>/dev/null; then
        log "ROCm SMI available"
        echo
        rocm-smi --showmeminfo vram 2>/dev/null || warn "Could not query VRAM info"
    else
        warn "rocm-smi not found"
    fi

    # Check amdgpu driver
    if lsmod | grep -q amdgpu; then
        log "amdgpu driver loaded"
        local vram_size
        vram_size=$(cat /sys/class/drm/card*/device/mem_info_vram_total 2>/dev/null | head -1)
        if [[ -n "$vram_size" ]]; then
            log "VRAM total (sysfs): $((vram_size / 1024 / 1024 / 1024)) GB"
        fi
    else
        warn "amdgpu driver not loaded"
    fi

    # Check for gfx1151 (Strix Halo)
    if dmesg 2>/dev/null | grep -qi "gfx1151\|strix"; then
        log "Strix Halo APU (gfx1151) detected"
    fi

    # Memory info
    local total_mem
    total_mem=$(free -g | awk '/^Mem:/{print $2}')
    log "Total system memory: ${total_mem}GB"
}

# Check current VRAM status
check_vram_status() {
    header "Current VRAM Status"

    local vram_total=0
    local vram_used=0

    # Try rocm-smi first
    if command -v rocm-smi &>/dev/null; then
        local vram_info
        vram_info=$(rocm-smi --showmeminfo vram 2>/dev/null || true)
        if [[ -n "$vram_info" ]]; then
            echo "$vram_info"
            echo
        fi
    fi

    # Try HIP device query
    if command -v hipInfo &>/dev/null; then
        log "HIP Device Info:"
        hipInfo 2>/dev/null | grep -E "totalGlobalMem|name" || true
    fi

    # Check sysfs
    for card in /sys/class/drm/card*/device; do
        if [[ -f "$card/mem_info_vram_total" ]]; then
            local total used
            total=$(cat "$card/mem_info_vram_total" 2>/dev/null || echo 0)
            used=$(cat "$card/mem_info_vram_used" 2>/dev/null || echo 0)
            log "sysfs VRAM: $((total / 1024 / 1024))MB total, $((used / 1024 / 1024))MB used"
        fi
    done
}

# Option 1: TTM Parameters (requires root)
apply_ttm_fix() {
    header "Option 1: TTM Kernel Parameters"

    if [[ $EUID -ne 0 ]]; then
        error "This option requires root privileges"
        echo "Run: sudo $0 --ttm"
        return 1
    fi

    log "Applying TTM parameters for large VRAM..."

    # Backup current modprobe config
    local modprobe_file="/etc/modprobe.d/amdgpu-ttm.conf"
    if [[ -f "$modprobe_file" ]]; then
        cp "$modprobe_file" "${modprobe_file}.bak"
        log "Backed up existing config"
    fi

    # Calculate TTM size based on total memory
    local total_mem_kb
    total_mem_kb=$(grep MemTotal /proc/meminfo | awk '{print $2}')
    local ttm_pages=$((total_mem_kb / 4))  # 4KB pages

    cat > "$modprobe_file" << EOF
# AMD GPU TTM parameters for large unified memory configs
# Generated by rocm-vram-fix.sh on $(date)
#
# For Strix Halo APUs with 96GB+ VRAM
options amdgpu vm_size=1024
options amdgpu vm_fragment_size=9
options amdgpu mes=1
options ttm pages_limit=$ttm_pages
EOF

    log "Created $modprobe_file"
    cat "$modprobe_file"

    echo
    warn "Reboot required to apply TTM changes"
    warn "After reboot, verify with: rocm-smi --showmeminfo vram"

    # Also update kernel parameters if using GRUB
    if [[ -f /etc/default/grub ]]; then
        log "Consider adding to GRUB_CMDLINE_LINUX:"
        echo "  amdgpu.vm_size=1024 amdgpu.mes=1"
    fi
}

# Option 2: UMA Build recommendations
recommend_uma_build() {
    header "Option 2: UMA Build (Recommended for APUs)"

    log "For AMD APUs with unified memory, use the UMA build of llama.cpp"
    echo

    cat << 'EOF'
The UMA (Unified Memory Access) build enables hipMemAdviseSetCoarseGrain
which allows the GPU to efficiently use unified memory without explicit
VRAM allocation limits.

Build command:
    cmake -B build-uma \
        -DGGML_HIP=ON \
        -DGGML_HIP_UMA=ON \
        -DAMDGPU_TARGETS=gfx1151

Runtime flags (REQUIRED):
    --no-mmap              # Don't use memory-mapped files
    --flash-attn on        # Enable flash attention
    --cache-type-k q8_0    # Quantized KV cache (saves ~50% memory)
    --cache-type-v q8_0

Memory usage with UMA:
- Model is loaded into unified memory
- KV cache allocated from unified memory pool
- No explicit VRAM limit (uses system memory)
- ROCm manages memory migration automatically

Example startup:
    ./build-uma/bin/llama-server \
        --model ~/models/Devstral-24B-Q4_K_M.gguf \
        --ctx-size 131072 \
        --n-gpu-layers 999 \
        --flash-attn on \
        --cache-type-k q8_0 \
        --cache-type-v q8_0 \
        --no-mmap

Or use: ./scripts/build-llama-uma.sh
EOF
}

# Option 3: Vulkan fallback
recommend_vulkan() {
    header "Option 3: Vulkan Backend (Fallback)"

    log "If ROCm/HIP issues persist, Vulkan is a reliable fallback"
    echo

    cat << 'EOF'
Vulkan advantages:
- Cross-platform compatibility
- Stable memory management
- Works with any GPU vendor

Vulkan disadvantages:
- ~50% slower than optimized HIP/ROCm
- No UMA optimization for APUs
- Flash attention may not be available

Build command:
    cmake -B build-vulkan -DGGML_VULKAN=ON

Or use: ./scripts/build-llama-vulkan.sh

Check Vulkan devices:
    vulkaninfo --summary
EOF
}

# Runtime environment setup
setup_runtime_env() {
    header "Runtime Environment Variables"

    cat << 'EOF'
Add these to your shell profile (~/.bashrc or ~/.zshrc):

# ROCm/HIP environment
export HSA_OVERRIDE_GFX_VERSION=11.5.1    # For gfx1151
export HIP_VISIBLE_DEVICES=0               # Use first GPU
export GPU_MAX_HW_QUEUES=8                 # Optimize queue usage

# Memory management
export HSA_ENABLE_SDMA=0                   # Disable SDMA (can help with UMA)
export AMD_SERIALIZE_KERNEL=3              # Serialize kernel launches

# Debug (optional)
export AMD_LOG_LEVEL=1                     # Minimal logging
export HIP_LAUNCH_BLOCKING=0               # Async kernel launches

# For large context (>128K)
export GPU_MAX_HEAP_SIZE=99                # Use 99% of available VRAM
export GPU_MAX_ALLOC_PERCENT=99

EOF

    log "Export these variables before running llama-server"
}

# Systemd service recommendations
recommend_systemd() {
    header "Systemd Service Setup"

    cat << 'EOF'
For production deployments, use a systemd service:

Create /etc/systemd/system/llama-server@.service:

[Unit]
Description=LLaMA Server (%i)
After=network.target

[Service]
Type=simple
User=llama
Group=llama
Environment="HSA_OVERRIDE_GFX_VERSION=11.5.1"
Environment="HIP_VISIBLE_DEVICES=0"
ExecStart=/opt/llama.cpp/build-uma/bin/llama-server \
    --model /models/%i.gguf \
    --host 0.0.0.0 \
    --port 8000 \
    --ctx-size 131072 \
    --n-gpu-layers 999 \
    --flash-attn on \
    --cache-type-k q8_0 \
    --cache-type-v q8_0 \
    --no-mmap
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target

Usage:
    sudo systemctl enable llama-server@devstral
    sudo systemctl start llama-server@devstral
EOF
}

# Main menu
show_menu() {
    header "ROCm VRAM Fix Options"

    echo -e "${CYAN}1)${NC} Apply TTM kernel parameters (requires root + reboot)"
    echo -e "${CYAN}2)${NC} Show UMA build recommendations (recommended)"
    echo -e "${CYAN}3)${NC} Show Vulkan fallback instructions"
    echo -e "${CYAN}4)${NC} Show runtime environment setup"
    echo -e "${CYAN}5)${NC} Show systemd service template"
    echo -e "${CYAN}6)${NC} Run full diagnostics"
    echo -e "${CYAN}q)${NC} Quit"
    echo

    read -rp "Select option [1-6/q]: " choice

    case "$choice" in
        1) apply_ttm_fix ;;
        2) recommend_uma_build ;;
        3) recommend_vulkan ;;
        4) setup_runtime_env ;;
        5) recommend_systemd ;;
        6)
            detect_system
            check_vram_status
            ;;
        q|Q) exit 0 ;;
        *) warn "Invalid option" ;;
    esac
}

# CLI interface
main() {
    case "${1:-}" in
        --ttm)
            apply_ttm_fix
            ;;
        --uma)
            recommend_uma_build
            ;;
        --vulkan)
            recommend_vulkan
            ;;
        --env)
            setup_runtime_env
            ;;
        --systemd)
            recommend_systemd
            ;;
        --diagnose|-d)
            detect_system
            check_vram_status
            ;;
        --help|-h)
            echo "Usage: $0 [option]"
            echo
            echo "Options:"
            echo "  --ttm       Apply TTM kernel parameters (requires root)"
            echo "  --uma       Show UMA build recommendations"
            echo "  --vulkan    Show Vulkan fallback instructions"
            echo "  --env       Show runtime environment setup"
            echo "  --systemd   Show systemd service template"
            echo "  --diagnose  Run system diagnostics"
            echo "  --help      Show this help"
            echo
            echo "Without arguments, shows interactive menu"
            ;;
        "")
            detect_system
            check_vram_status
            echo
            show_menu
            ;;
        *)
            error "Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
}

main "$@"
