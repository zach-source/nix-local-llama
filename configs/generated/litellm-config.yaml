# LiteLLM Proxy Configuration
# Generated by nix/llm-config.nix
# Provides OpenAI-compatible model aliasing

model_list:
  # Chat/Completions models → port 8000
- model_name: gpt-4
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: gpt-4-turbo
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: gpt-4o
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: gpt-3.5-turbo
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: claude-3-opus
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: claude-3-sonnet
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: devstral
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: devstral-2
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: mistral-large
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: devstral
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: devstral2
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"

- model_name: mistral-coder
  litellm_params:
    model: openai/devstral
    api_base: http://localhost:8000/v1
    api_key: "sk-local"


  # Embedding models → port 8001
- model_name: text-embedding-ada-002
  litellm_params:
    model: openai/qwen3-embed
    api_base: http://localhost:8001/v1
    api_key: "sk-local"

- model_name: text-embedding-3-small
  litellm_params:
    model: openai/qwen3-embed
    api_base: http://localhost:8001/v1
    api_key: "sk-local"

- model_name: text-embedding-3-large
  litellm_params:
    model: openai/qwen3-embed
    api_base: http://localhost:8001/v1
    api_key: "sk-local"

- model_name: qwen3-embed
  litellm_params:
    model: openai/qwen3-embed
    api_base: http://localhost:8001/v1
    api_key: "sk-local"


  # Reranking models → port 8002
- model_name: rerank-english-v3.0
  litellm_params:
    model: openai/bge-reranker
    api_base: http://localhost:8002/v1
    api_key: "sk-local"

- model_name: rerank-multilingual-v3.0
  litellm_params:
    model: openai/bge-reranker
    api_base: http://localhost:8002/v1
    api_key: "sk-local"

- model_name: bge-reranker
  litellm_params:
    model: openai/bge-reranker
    api_base: http://localhost:8002/v1
    api_key: "sk-local"

- model_name: rerank
  litellm_params:
    model: openai/bge-reranker
    api_base: http://localhost:8002/v1
    api_key: "sk-local"


litellm_settings:
  cache: true
  cache_params:
    type: "local"
    ttl: 3600
  request_timeout: 600

general_settings:
  master_key: "sk-local-llm-master"

