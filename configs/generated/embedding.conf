# Configuration for Qwen3-Embedding-8B
# Generated by nix/llm-config.nix
# Service: llama-server@embedding

# Binary path
LLAMA_BIN=/home/ztaylor/llama.cpp/build-rocm/bin/llama-server

# Model path
MODEL_PATH=/home/ztaylor/models/Qwen3-Embedding-8B-Q8_0.gguf

# Server settings
HOST=0.0.0.0
PORT=8001

# Context and GPU
CTX_SIZE=8192
N_GPU_LAYERS=999

# Mode-specific and hardware flags
EXTRA_FLAGS=--flash-attn on --cache-type-k q8_0 --cache-type-v q8_0 --no-mmap -fit off --n-gpu-layers 999 --embedding --pooling mean --parallel 4 --threads 8

