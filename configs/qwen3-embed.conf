# Configuration for Qwen3-Embedding-8B model
# Copy to: /etc/llama-server/qwen3-embed.conf
# Used with: systemctl start llama-server@qwen3-embed

# Binary path
LLAMA_BIN=/home/ztaylor/llama.cpp/build-rocm/bin/llama-server

# Model path
MODEL_PATH=/home/ztaylor/models/Qwen3-Embedding-8B-Q8_0.gguf

# Server settings
HOST=0.0.0.0
PORT=8001

# Context and GPU - embeddings use smaller context
CTX_SIZE=8192
N_GPU_LAYERS=999

# Embeddings mode
EXTRA_FLAGS=--embedding --pooling mean --parallel 4 --flash-attn on --no-mmap --threads 8
